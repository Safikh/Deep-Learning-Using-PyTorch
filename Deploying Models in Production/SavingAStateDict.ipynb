{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/wine_data.csv')\n",
    "features = df.drop('Class', axis=1)\n",
    "labels = df[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_ = torch.from_numpy(X_train.values).float()\n",
    "Xtest_ = torch.from_numpy(X_test.values).float()\n",
    "ytrain_ = torch.from_numpy(y_train.values).long().view(1, -1)[0]\n",
    "ytest_ = torch.from_numpy(y_test.values).long().view(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\n",
    "output_size = 3\n",
    "hidden_size = 100\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "\n",
    "    def forward(self, X):\n",
    "        X = torch.sigmoid(self.fc1(X))\n",
    "        X = torch.sigmoid(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return F.log_softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.1809\n",
      "Epoch: 200, Loss: 0.0500\n",
      "Epoch: 300, Loss: 0.0282\n",
      "Epoch: 400, Loss: 0.4018\n",
      "Epoch: 500, Loss: 0.0724\n",
      "Epoch: 600, Loss: 0.0480\n",
      "Epoch: 700, Loss: 0.0430\n",
      "Epoch: 800, Loss: 0.0407\n",
      "Epoch: 900, Loss: 0.0394\n",
      "Epoch: 1000, Loss: 0.0386\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.NLLLoss()\n",
    "EPOCHS = 1000\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(Xtrain_)\n",
    "    loss = loss_fn(y_pred, ytrain_)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch: {epoch + 1}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.1120,  0.2563, -0.0408,  ..., -0.1652,  0.0526,  0.2510],\n",
       "                      [-0.0658,  0.1725, -0.0683,  ..., -0.1469,  0.1052,  0.1421],\n",
       "                      [ 0.2472, -0.1066, -0.0062,  ...,  0.1169, -0.0348, -0.0889],\n",
       "                      ...,\n",
       "                      [ 0.2008, -0.0506,  0.0597,  ..., -0.0054,  0.0826, -0.1437],\n",
       "                      [-0.1649,  0.1275, -0.2037,  ...,  0.0156, -0.1733, -0.2591],\n",
       "                      [-0.0364, -0.2594,  0.0709,  ...,  0.2054,  0.0909,  0.1273]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.1240,  0.0435,  0.2725, -0.2136,  0.1732,  0.0043,  0.1174,  0.0205,\n",
       "                       0.0053,  0.0290,  0.0879,  0.1010,  0.1737,  0.1239,  0.2463,  0.0033,\n",
       "                      -0.0974, -0.1516, -0.2644,  0.0479, -0.2284,  0.0653,  0.2585, -0.1969,\n",
       "                      -0.1416, -0.0053, -0.0455,  0.2659, -0.4787, -0.0153,  0.2852, -0.2508,\n",
       "                       0.2635, -0.4896, -0.1568, -0.2311,  0.1607, -0.0842, -0.1383,  0.1848,\n",
       "                      -0.0355,  0.0750,  0.2680,  0.2190,  0.0618, -0.0282, -0.2106, -0.3603,\n",
       "                       0.1974, -0.0553, -0.0532, -0.1646, -0.2332, -0.3434,  0.1812,  0.1835,\n",
       "                       0.0460,  0.4644, -0.0509,  0.0803, -0.0044,  0.1710,  0.1067, -0.0025,\n",
       "                       0.1887,  0.2178, -0.1493,  0.8652, -0.0089, -0.1815, -0.1580,  0.2639,\n",
       "                      -0.0753, -0.1452, -0.1444,  0.2741, -0.1446, -0.7794, -0.0100,  0.1987,\n",
       "                      -0.1608, -0.2039,  0.1516, -0.2621, -0.1449, -0.1580, -0.0975, -0.1749,\n",
       "                       0.1020, -0.2213, -0.0154, -0.2501, -0.0130, -0.2187, -0.1527,  0.2214,\n",
       "                       0.2573, -0.0800,  0.2381, -0.1683])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0347,  0.1353, -0.0262,  ...,  0.0622, -0.0705,  0.1099],\n",
       "                      [-0.0141,  0.1190,  0.0897,  ..., -0.0899, -0.0061, -0.0460],\n",
       "                      [-0.0255,  0.0214, -0.0479,  ...,  0.0241, -0.0395, -0.0172],\n",
       "                      ...,\n",
       "                      [-0.0080, -0.0850,  0.0949,  ..., -0.0252, -0.0544, -0.0625],\n",
       "                      [ 0.0636,  0.0456, -0.0778,  ...,  0.0473, -0.0734,  0.0477],\n",
       "                      [ 0.0268, -0.0813, -0.0679,  ...,  0.0653, -0.0061, -0.1035]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0941,  0.0815,  0.0279, -0.0794, -0.1587,  0.0060,  0.0148, -0.0179,\n",
       "                       0.0846, -0.1072, -0.0294,  0.0340,  0.0223, -0.1263, -0.0528, -0.1667,\n",
       "                       0.1418, -0.2304, -0.0473, -0.1251,  0.0579,  0.0355,  0.0346, -0.0315,\n",
       "                      -0.0537, -0.0400, -0.0678, -0.1215,  0.0434, -0.3089,  0.0113, -0.0250,\n",
       "                       0.0060, -0.0437,  0.0040, -0.0692, -0.0373, -0.0805, -0.0646,  0.0184,\n",
       "                       0.0707,  0.0186,  0.0206, -0.0173, -0.0784, -0.0210, -0.0204, -0.0589,\n",
       "                       0.0103,  0.0124,  0.0229,  0.1167, -0.0438, -0.0598,  0.0853,  0.0564,\n",
       "                      -0.0297, -0.0741, -0.1243, -0.0517,  0.0919, -0.0497, -0.0741,  0.0227,\n",
       "                       0.0815,  0.0794,  0.0409, -0.1373,  0.0032,  0.0144, -0.0869, -0.1309,\n",
       "                      -0.0337, -0.0717, -0.0715,  0.0836,  0.0239, -0.0750, -0.0523, -0.0327,\n",
       "                      -0.0272, -0.1008, -0.0190, -0.0887, -0.0343,  0.0140, -0.0350, -0.0688,\n",
       "                      -0.0471, -0.0458, -0.0300,  0.0298,  0.0417,  0.0400,  0.0535,  0.1196,\n",
       "                       0.0951, -0.0476,  0.0800,  0.0160])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.1272, -0.3645, -0.1832, -0.1114, -0.1428,  0.5139,  0.4548, -0.2086,\n",
       "                        0.5079, -0.0732, -0.2395, -0.4255,  0.2937, -0.1708,  0.0609,  0.0700,\n",
       "                        0.0207, -0.0770, -0.4265, -0.1815,  0.3270, -0.4784, -0.2907, -0.5634,\n",
       "                       -0.0914,  0.0282, -0.0212, -0.1531, -0.3958, -0.0439, -0.1603, -0.8818,\n",
       "                       -0.1883,  0.3672,  0.3043,  0.4834, -0.1833, -0.2482, -0.0850, -0.2685,\n",
       "                        0.1900,  0.4370, -0.3087,  0.1625, -0.1149, -0.3933,  0.2754,  0.5002,\n",
       "                       -0.0479, -0.6492, -0.1247, -0.4706, -0.1074, -0.0868,  0.1497,  0.2711,\n",
       "                        0.4575, -0.4726, -0.2546, -0.5560,  0.3594, -0.0991, -0.5402, -0.1946,\n",
       "                        0.3312, -0.3327,  0.3527,  0.2298,  0.2712, -0.3708,  0.2918, -0.1736,\n",
       "                        0.1769, -0.5356, -0.2833,  0.3419,  0.3278, -0.4908,  0.4804, -0.0874,\n",
       "                        0.3755, -0.1319,  0.4024, -0.1812, -0.0096,  0.1626,  0.3261, -0.3454,\n",
       "                        0.1723,  0.3357, -0.5570,  0.3617, -0.0524,  0.1425,  0.5940,  0.2230,\n",
       "                        0.3286, -0.1995, -0.7152, -0.1748],\n",
       "                      [-0.4155, -0.1682, -0.4662,  0.2571,  0.1838, -0.2755,  0.4028,  0.3602,\n",
       "                       -0.1433,  0.6585,  0.3555, -0.2411, -0.5450,  0.5416,  0.4896,  0.1416,\n",
       "                       -0.5958, -0.0550,  0.0723,  0.2035,  0.3971,  0.3549, -0.4178,  0.2116,\n",
       "                        0.5968,  0.0911,  0.4986,  0.2238, -0.5599, -0.0544,  0.3041,  0.1094,\n",
       "                        0.3716, -0.2803, -0.3681, -0.1737, -0.5866,  0.4679,  0.3157,  0.3545,\n",
       "                       -0.7081, -0.2836, -0.0070, -0.5000,  0.4137,  0.2803, -0.4373,  0.2018,\n",
       "                        0.5499, -0.3392,  0.5653, -0.5679,  0.4658,  0.2262, -0.5199, -0.3854,\n",
       "                       -0.0863, -0.1057,  0.5307, -0.5802, -0.4468,  0.5616, -0.1909,  0.3751,\n",
       "                       -0.5214, -0.4866, -0.2782,  0.3253, -0.5447,  0.2669,  0.3664,  0.4232,\n",
       "                       -0.5557, -0.2298,  0.2016, -0.4572, -0.5296,  0.0659, -0.1240,  0.4972,\n",
       "                       -0.4506,  0.3437, -0.4592,  0.5815,  0.3709,  0.3683, -0.4692,  0.3577,\n",
       "                        0.2134,  0.3072, -0.2377, -0.4148, -0.6145, -0.4293, -0.5733, -0.4045,\n",
       "                       -0.4966,  0.5623, -0.1658,  0.3622],\n",
       "                      [ 0.0539,  0.5668,  0.3634, -0.1887,  0.1527, -0.3215, -0.7025, -0.1108,\n",
       "                       -0.4101, -0.4262, -0.1406,  0.5481,  0.0607, -0.2452, -0.4780, -0.1185,\n",
       "                        0.3300, -0.0041,  0.3248,  0.1642, -0.5738,  0.2155,  0.5185,  0.3448,\n",
       "                       -0.3752, -0.2092, -0.3693,  0.1101,  0.6543,  0.0820, -0.1654,  0.5118,\n",
       "                       -0.2290, -0.1962, -0.1176, -0.4387,  0.5193, -0.2060,  0.0250, -0.0262,\n",
       "                        0.3240, -0.2848,  0.3717,  0.1536, -0.2533,  0.0201, -0.0362, -0.7965,\n",
       "                       -0.3299,  0.6667, -0.2445,  0.7003, -0.3853, -0.1750,  0.3298, -0.1825,\n",
       "                       -0.4320,  0.4692,  0.0316,  0.8226,  0.0767, -0.3355,  0.5462, -0.1852,\n",
       "                       -0.1663,  0.5770, -0.3852, -0.5624,  0.1583,  0.0491, -0.6690,  0.0513,\n",
       "                       -0.0051,  0.6130,  0.0801, -0.1553,  0.1686,  0.4989, -0.3015, -0.4449,\n",
       "                       -0.2798, -0.1336, -0.3191, -0.2659, -0.1506, -0.4760,  0.0159,  0.1673,\n",
       "                       -0.2807, -0.4287,  0.6450, -0.0185,  0.4387,  0.2284, -0.3948,  0.0172,\n",
       "                        0.0647, -0.2516,  0.7416,  0.0566]])),\n",
       "             ('fc3.bias', tensor([ 0.1796, -0.1607, -0.0401]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'step': 1000,\n",
       "   'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00],\n",
       "           [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
       "            -5.6052e-45, -5.6052e-45],\n",
       "           [ 4.5222e-20,  9.9032e-21,  8.0828e-21,  ...,  4.0855e-21,\n",
       "             1.1999e-20,  1.0817e-18],\n",
       "           ...,\n",
       "           [ 2.3166e-30,  5.2701e-31,  4.1767e-31,  ...,  2.1463e-31,\n",
       "             6.2094e-31,  5.4833e-29],\n",
       "           [-7.8384e-40, -1.8015e-40, -1.4155e-40,  ..., -7.3225e-41,\n",
       "            -2.1041e-40, -1.8505e-38],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "             0.0000e+00,  0.0000e+00]]),\n",
       "   'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00],\n",
       "           [2.9561e-13, 8.0763e-15, 9.4486e-15,  ..., 2.3338e-15, 1.8574e-14,\n",
       "            2.0139e-10],\n",
       "           [2.6139e-38, 1.2485e-39, 8.3641e-40,  ..., 2.1377e-40, 1.8471e-39,\n",
       "            1.4940e-35],\n",
       "           ...,\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00],\n",
       "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            0.0000e+00]])},\n",
       "  1: {'step': 1000,\n",
       "   'exp_avg': tensor([ 0.0000e+00, -5.6052e-45,  3.6789e-21,  7.9843e-20,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00, -2.4688e-24,  0.0000e+00, -5.6052e-45,\n",
       "            0.0000e+00, -1.2691e-24, -7.6166e-22, -9.0456e-20, -5.1443e-33,\n",
       "           -5.6052e-45,  0.0000e+00,  0.0000e+00,  7.4377e-29,  0.0000e+00,\n",
       "            6.0941e-24,  0.0000e+00, -1.0882e-32,  1.6417e-19, -5.6052e-45,\n",
       "            0.0000e+00,  5.9622e-23,  0.0000e+00,  8.9777e-20,  0.0000e+00,\n",
       "            3.8000e-07,  2.0743e-33,  0.0000e+00,  1.0003e-23,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  7.7960e-28,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00, -3.7449e-21,  0.0000e+00,  0.0000e+00, -4.0077e-33,\n",
       "            6.5175e-25, -5.6052e-45, -5.6009e-33, -5.6052e-45, -2.2524e-32,\n",
       "            5.0399e-19,  6.4767e-20, -7.2751e-35, -4.9454e-12,  3.8703e-27,\n",
       "           -1.7662e-20, -2.3881e-18, -4.7135e-27,  0.0000e+00, -1.0191e-27,\n",
       "            0.0000e+00, -7.3703e-19,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00, -6.0694e-05, -1.9855e-24,  1.0047e-28,\n",
       "           -2.0725e-35, -2.0529e-40,  0.0000e+00,  0.0000e+00, -3.8691e-19,\n",
       "           -5.6052e-45, -4.2011e-20,  1.3694e-04,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00,  3.6500e-36,  5.9164e-31, -3.3811e-23,\n",
       "            1.6582e-16,  0.0000e+00,  2.8634e-30,  8.9349e-40,  0.0000e+00,\n",
       "           -1.4170e-13,  0.0000e+00, -7.4349e-37,  0.0000e+00, -3.0482e-13,\n",
       "            0.0000e+00,  0.0000e+00,  1.8847e-31, -6.3776e-41,  0.0000e+00]),\n",
       "   'exp_avg_sq': tensor([0.0000e+00, 1.9666e-15, 1.7307e-40, 6.2624e-23, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6794e-24, 0.0000e+00, 6.1937e-43,\n",
       "           3.8115e-43, 5.0664e-22, 1.5694e-06, 3.7107e-08, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 2.2421e-44, 0.0000e+00, 2.9757e-05, 8.9533e-09,\n",
       "           8.9350e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0965e-08, 0.0000e+00,\n",
       "           2.2971e-04, 0.0000e+00, 0.0000e+00, 1.7523e-08, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7537e-41,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6406e-22, 1.4585e-06,\n",
       "           8.4737e-13, 0.0000e+00, 1.8171e-37, 5.3465e-38, 0.0000e+00, 3.9677e-06,\n",
       "           0.0000e+00, 2.0032e-40, 8.9809e-25, 4.4886e-05, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 3.4017e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 4.9300e-05, 1.8217e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 6.9555e-24, 1.4682e-08, 2.0266e-35, 6.8080e-06,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           0.0000e+00, 2.0965e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "           4.9225e-27, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5192e-13, 0.0000e+00,\n",
       "           0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])},\n",
       "  2: {'step': 1000,\n",
       "   'exp_avg': tensor([[ 9.1993e-08,  9.1993e-08,  2.3045e-20,  ...,  2.0731e-30,\n",
       "             7.5627e-40,  9.1936e-08],\n",
       "           [-2.5231e-06, -2.5231e-06, -5.8431e-21,  ..., -5.3156e-31,\n",
       "            -1.9395e-40, -2.5231e-06],\n",
       "           [-1.1814e-06, -1.1814e-06,  1.2468e-20,  ...,  1.1175e-30,\n",
       "             4.0763e-40, -1.1814e-06],\n",
       "           ...,\n",
       "           [ 3.3994e-07,  3.3994e-07, -3.2937e-20,  ..., -2.9618e-30,\n",
       "            -1.0805e-39,  3.4000e-07],\n",
       "           [-4.7696e-06, -4.7696e-06, -1.8977e-20,  ..., -1.7158e-30,\n",
       "            -6.2600e-40, -4.7696e-06],\n",
       "           [-4.2400e-07, -4.2400e-07, -2.3409e-20,  ..., -2.1073e-30,\n",
       "            -7.6875e-40, -4.2400e-07]]),\n",
       "   'exp_avg_sq': tensor([[2.9083e-06, 2.9083e-06, 4.0227e-40,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            2.9083e-06],\n",
       "           [1.2959e-05, 1.2959e-05, 7.8169e-40,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            1.2959e-05],\n",
       "           [6.8750e-06, 6.8750e-06, 4.4512e-40,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            6.8750e-06],\n",
       "           ...,\n",
       "           [1.0561e-05, 1.0560e-05, 2.6412e-39,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            1.0561e-05],\n",
       "           [2.5813e-05, 2.5813e-05, 2.0826e-39,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            2.5813e-05],\n",
       "           [4.3510e-06, 4.3510e-06, 3.7103e-40,  ..., 0.0000e+00, 0.0000e+00,\n",
       "            4.3510e-06]])},\n",
       "  3: {'step': 1000,\n",
       "   'exp_avg': tensor([ 9.1951e-08, -2.5231e-06, -1.1814e-06, -2.7602e-06, -2.9643e-06,\n",
       "            1.9089e-06,  3.5203e-06,  2.1254e-07,  2.8392e-06,  6.4581e-07,\n",
       "            9.8862e-08, -2.8557e-06,  3.4639e-07,  3.1029e-07,  1.0260e-06,\n",
       "           -3.7409e-07, -5.7663e-07,  4.6074e-09, -2.3303e-06, -4.4279e-06,\n",
       "            2.6028e-06, -1.3022e-06, -2.0349e-06, -2.4286e-06,  5.6175e-07,\n",
       "           -2.0292e-07,  7.0373e-07, -1.4645e-06, -2.6571e-06,  1.1336e-10,\n",
       "            2.7967e-07, -3.7108e-06,  3.2120e-07,  9.4856e-07,  6.1055e-07,\n",
       "            2.9679e-06, -1.4774e-06,  1.3732e-07,  9.4564e-08, -6.9039e-08,\n",
       "            6.0740e-08,  1.5062e-06, -2.3138e-06,  1.4856e-07,  4.1356e-07,\n",
       "           -5.8156e-07,  3.2298e-07,  3.6444e-06,  6.7944e-07, -4.2235e-06,\n",
       "            2.2576e-07, -3.1447e-06,  5.3470e-07,  2.5091e-07, -1.8761e-07,\n",
       "            7.3686e-07,  2.9016e-06, -3.0917e-06, -1.6962e-07, -3.8138e-06,\n",
       "            3.4156e-07,  5.6451e-07, -3.5110e-06,  2.7342e-07,  6.8343e-07,\n",
       "           -2.3688e-06,  1.7104e-06,  2.1937e-06,  2.1181e-07, -7.1063e-07,\n",
       "            2.7128e-06, -5.1974e-08,  6.7276e-08, -3.6878e-06, -3.9229e-06,\n",
       "            6.5269e-07,  2.3330e-07, -3.1090e-06,  2.0844e-06,  7.9608e-07,\n",
       "            1.0593e-06,  2.6251e-07,  1.2403e-06,  2.2315e-07, -2.5845e-07,\n",
       "            1.5890e-06,  2.6468e-07, -9.0444e-07, -1.0243e-05,  2.2368e-06,\n",
       "           -3.8523e-06,  4.9524e-07, -1.1552e-06, -7.0264e-08,  1.4352e-06,\n",
       "           -2.7925e-08,  3.4486e-07,  3.3997e-07, -4.7696e-06, -4.2401e-07]),\n",
       "   'exp_avg_sq': tensor([2.9083e-06, 1.2959e-05, 6.8750e-06, 4.1816e-06, 2.7089e-06, 1.0778e-05,\n",
       "           2.3442e-05, 3.8691e-06, 1.0259e-05, 1.6906e-05, 3.7542e-06, 9.3111e-06,\n",
       "           7.2639e-06, 9.7521e-06, 1.3125e-05, 4.9223e-06, 1.2579e-05, 1.7923e-08,\n",
       "           6.7452e-06, 3.2208e-06, 1.5319e-05, 4.5603e-06, 9.5745e-06, 7.7579e-06,\n",
       "           1.4127e-05, 5.3111e-06, 1.0581e-05, 2.9088e-06, 1.7446e-05, 1.2044e-07,\n",
       "           2.9759e-06, 8.9195e-06, 4.6199e-06, 7.0364e-06, 4.7785e-06, 8.0130e-06,\n",
       "           1.2743e-05, 6.9537e-06, 1.7275e-06, 4.0169e-06, 1.9111e-05, 7.8056e-06,\n",
       "           6.8236e-06, 5.4901e-06, 5.8100e-06, 4.2965e-06, 5.1235e-06, 1.8008e-05,\n",
       "           1.1040e-05, 2.1151e-05, 8.7725e-06, 2.3126e-05, 8.2879e-06, 1.6990e-06,\n",
       "           1.0308e-05, 4.5816e-06, 6.7124e-06, 1.1044e-05, 5.9292e-06, 2.8067e-05,\n",
       "           5.1945e-06, 1.0781e-05, 1.6306e-05, 4.1896e-06, 7.7577e-06, 1.4772e-05,\n",
       "           6.8855e-06, 1.1051e-05, 9.1531e-06, 2.2665e-06, 1.5649e-05, 3.8704e-06,\n",
       "           5.2053e-06, 1.9195e-05, 4.5694e-06, 7.9966e-06, 1.0356e-05, 8.9150e-06,\n",
       "           8.9315e-06, 1.1505e-05, 8.4411e-06, 2.7359e-06, 9.9808e-06, 1.0391e-05,\n",
       "           4.9038e-06, 9.5483e-06, 6.3348e-06, 4.6931e-06, 8.8375e-06, 1.0261e-05,\n",
       "           2.3538e-05, 5.4281e-06, 1.7283e-05, 5.2621e-06, 2.2351e-05, 3.6963e-06,\n",
       "           6.6017e-06, 1.0561e-05, 2.5813e-05, 4.3510e-06])},\n",
       "  4: {'step': 1000,\n",
       "   'exp_avg': tensor([[-3.7143e-05,  1.5458e-04,  9.7548e-05, -2.9479e-05,  1.3331e-05,\n",
       "            -1.5759e-04, -2.1671e-04, -7.1944e-06, -1.8880e-04, -7.2462e-05,\n",
       "             4.0441e-06,  1.6812e-04, -4.7345e-05, -3.1406e-05, -1.2120e-04,\n",
       "            -4.2788e-06,  4.6873e-05, -5.2336e-08,  1.0059e-04,  2.3133e-05,\n",
       "            -1.9969e-04,  1.0714e-04,  1.2496e-04,  1.1388e-04, -6.3465e-05,\n",
       "            -1.7724e-06, -7.7148e-05,  3.3287e-07,  1.3939e-04, -3.5336e-09,\n",
       "            -1.4703e-05,  1.8603e-04, -1.7831e-05, -1.1888e-04, -1.0077e-04,\n",
       "            -2.0210e-04,  1.1156e-04, -1.1505e-05,  4.5815e-06,  2.3111e-05,\n",
       "             1.7802e-05, -1.5358e-04,  1.1786e-04, -9.6761e-06, -3.9959e-05,\n",
       "             5.4662e-05, -6.6958e-05, -2.1417e-04, -5.9201e-05,  1.8086e-04,\n",
       "            -4.0393e-05,  1.4903e-04, -6.0779e-05, -3.2570e-05,  2.6180e-05,\n",
       "            -1.1178e-04, -2.1415e-04,  1.5223e-04,  2.3419e-05,  1.6102e-04,\n",
       "            -6.2295e-05, -4.7969e-05,  1.7221e-04, -6.2618e-07, -9.3358e-05,\n",
       "             1.3403e-04, -1.6759e-04, -1.9001e-04, -2.1232e-05,  8.4261e-05,\n",
       "            -2.0027e-04,  1.9434e-05, -3.5462e-05,  1.7575e-04,  2.5806e-05,\n",
       "            -9.1358e-05, -3.6890e-05,  1.4303e-04, -1.6410e-04, -6.1533e-05,\n",
       "            -1.2724e-04, -1.5022e-05, -1.3261e-04, -3.4415e-05, -3.8538e-05,\n",
       "            -1.5627e-04, -5.9190e-05,  6.5090e-05, -4.7492e-05, -1.5603e-04,\n",
       "             1.6862e-04, -8.3891e-05,  7.1220e-05,  8.7023e-06, -1.2460e-04,\n",
       "            -4.6046e-05, -5.3610e-05, -2.4701e-05,  1.9303e-04,  8.2599e-06],\n",
       "           [ 1.0590e-04,  1.0844e-05,  5.8879e-05, -3.7639e-05, -1.5074e-05,\n",
       "             5.9762e-05, -8.6189e-06, -7.2283e-05,  3.5530e-05, -6.1154e-05,\n",
       "            -7.9008e-05,  3.6372e-05,  1.0636e-04, -7.3899e-05, -4.8896e-05,\n",
       "             1.6138e-06,  7.9435e-05, -1.5589e-08, -2.4666e-06, -1.6262e-05,\n",
       "            -1.0781e-05, -5.7697e-05,  3.8189e-05, -1.5060e-05, -6.4703e-05,\n",
       "             7.1407e-07, -5.6810e-05, -1.5243e-05,  4.6826e-05,  2.4317e-09,\n",
       "            -6.7804e-05, -8.1304e-06, -7.4212e-05,  7.2270e-05,  8.5153e-05,\n",
       "             2.8486e-05,  5.6570e-05, -8.3584e-05, -5.5212e-05, -6.3792e-05,\n",
       "             9.9854e-05,  6.7467e-05,  1.4548e-05,  1.0915e-04, -6.8533e-05,\n",
       "            -5.5525e-05,  9.6672e-05,  9.2723e-06, -5.8497e-05,  3.8155e-05,\n",
       "            -8.3046e-05,  4.0058e-05, -7.0960e-05, -5.9097e-05,  9.3971e-05,\n",
       "             8.2329e-05,  2.2209e-05,  2.0053e-05, -7.5322e-05,  4.5654e-05,\n",
       "             1.1615e-04, -7.0359e-05,  2.5721e-05, -7.2929e-05,  9.9864e-05,\n",
       "             4.6648e-05,  6.0336e-05, -1.7007e-05,  1.0126e-04, -8.4666e-05,\n",
       "            -1.5345e-05, -7.1229e-05,  9.5082e-05,  2.9960e-05, -2.9848e-05,\n",
       "             8.8291e-05,  1.0480e-04,  9.1998e-06,  4.6962e-05, -6.2367e-05,\n",
       "             8.5875e-05, -7.4203e-05,  7.8540e-05, -8.1784e-05, -4.6862e-05,\n",
       "            -2.2668e-05,  9.5825e-05, -3.6165e-05,  1.5094e-05,  7.5948e-06,\n",
       "             2.6009e-05,  1.0417e-04,  6.0108e-05,  9.9064e-05,  8.6268e-05,\n",
       "             9.2158e-05,  1.0529e-04, -7.3924e-05,  2.2522e-05, -5.0075e-05],\n",
       "           [-6.8756e-05, -1.6542e-04, -1.5643e-04,  6.7118e-05,  1.7429e-06,\n",
       "             9.7827e-05,  2.2533e-04,  7.9477e-05,  1.5327e-04,  1.3361e-04,\n",
       "             7.4964e-05, -2.0449e-04, -5.9011e-05,  1.0530e-04,  1.7009e-04,\n",
       "             2.6650e-06, -1.2631e-04,  6.7924e-08, -9.8123e-05, -6.8709e-06,\n",
       "             2.1047e-04, -4.9443e-05, -1.6315e-04, -9.8824e-05,  1.2817e-04,\n",
       "             1.0583e-06,  1.3396e-04,  1.4910e-05, -1.8621e-04,  1.1019e-09,\n",
       "             8.2506e-05, -1.7790e-04,  9.2043e-05,  4.6610e-05,  1.5616e-05,\n",
       "             1.7362e-04, -1.6813e-04,  9.5089e-05,  5.0630e-05,  4.0680e-05,\n",
       "            -1.1766e-04,  8.6117e-05, -1.3241e-04, -9.9476e-05,  1.0849e-04,\n",
       "             8.6268e-07, -2.9715e-05,  2.0490e-04,  1.1770e-04, -2.1902e-04,\n",
       "             1.2344e-04, -1.8908e-04,  1.3174e-04,  9.1666e-05, -1.2015e-04,\n",
       "             2.9449e-05,  1.9194e-04, -1.7228e-04,  5.1903e-05, -2.0667e-04,\n",
       "            -5.3852e-05,  1.1833e-04, -1.9793e-04,  7.3554e-05, -6.5065e-06,\n",
       "            -1.8068e-04,  1.0725e-04,  2.0701e-04, -8.0031e-05,  4.0511e-07,\n",
       "             2.1562e-04,  5.1795e-05, -5.9621e-05, -2.0571e-04,  4.0419e-06,\n",
       "             3.0667e-06, -6.7907e-05, -1.5223e-04,  1.1714e-04,  1.2390e-04,\n",
       "             4.1367e-05,  8.9225e-05,  5.4066e-05,  1.1620e-04,  8.5401e-05,\n",
       "             1.7893e-04, -3.6636e-05, -2.8926e-05,  3.2398e-05,  1.4844e-04,\n",
       "            -1.9463e-04, -2.0284e-05, -1.3133e-04, -1.0777e-04,  3.8329e-05,\n",
       "            -4.6112e-05, -5.1682e-05,  9.8625e-05, -2.1556e-04,  4.1815e-05]]),\n",
       "   'exp_avg_sq': tensor([[1.6466e-04, 1.8649e-04, 9.7250e-05, 5.9687e-05, 6.3366e-05, 1.7066e-04,\n",
       "            1.9868e-04, 7.0077e-05, 2.1349e-04, 6.4295e-05, 7.2551e-05, 9.4437e-05,\n",
       "            1.6458e-04, 7.5402e-05, 1.1123e-04, 9.9655e-05, 1.4629e-04, 1.2813e-05,\n",
       "            5.7860e-05, 6.1111e-05, 1.7194e-04, 5.3766e-05, 6.8599e-05, 4.5428e-05,\n",
       "            7.2334e-05, 9.4979e-05, 8.5881e-05, 5.6295e-05, 6.8003e-05, 4.5829e-05,\n",
       "            7.5509e-05, 4.4873e-05, 6.1520e-05, 1.3547e-04, 1.5028e-04, 2.5577e-04,\n",
       "            9.4516e-05, 7.0455e-05, 5.8922e-05, 7.5230e-05, 1.8346e-04, 1.8616e-04,\n",
       "            8.4148e-05, 1.6281e-04, 7.0495e-05, 5.5728e-05, 1.6616e-04, 1.4268e-04,\n",
       "            6.5119e-05, 9.2101e-05, 7.6932e-05, 7.9693e-05, 6.6567e-05, 7.3667e-05,\n",
       "            1.5224e-04, 1.6694e-04, 2.2144e-04, 9.1431e-05, 6.2478e-05, 6.6952e-05,\n",
       "            1.2611e-04, 5.8013e-05, 1.4316e-04, 4.7976e-05, 1.3004e-04, 8.4177e-05,\n",
       "            1.6893e-04, 1.5778e-04, 1.7648e-04, 7.7767e-05, 1.4034e-04, 7.2871e-05,\n",
       "            1.2399e-04, 1.4158e-04, 6.2967e-05, 1.2895e-04, 1.9527e-04, 6.2434e-05,\n",
       "            1.6532e-04, 5.7696e-05, 1.7821e-04, 7.6596e-05, 1.6428e-04, 6.8424e-05,\n",
       "            7.6626e-05, 1.3207e-04, 1.2945e-04, 5.0692e-05, 1.0192e-04, 1.0878e-04,\n",
       "            1.3653e-04, 1.3845e-04, 1.2883e-04, 1.5632e-04, 1.4768e-04, 1.4853e-04,\n",
       "            1.4508e-04, 5.9648e-05, 1.1682e-04, 7.1131e-05],\n",
       "           [1.0197e-04, 2.0336e-04, 6.8151e-05, 7.9139e-05, 9.5614e-05, 1.1785e-04,\n",
       "            2.2194e-04, 1.3506e-04, 1.7154e-04, 1.0623e-04, 1.2926e-04, 8.0080e-05,\n",
       "            1.0451e-04, 1.1337e-04, 1.4837e-04, 9.3802e-05, 9.7200e-05, 5.8119e-06,\n",
       "            8.0131e-05, 9.5840e-05, 2.0390e-04, 1.4077e-04, 5.5764e-05, 9.0398e-05,\n",
       "            1.1413e-04, 9.2918e-05, 1.1872e-04, 9.7438e-05, 6.3162e-05, 4.5020e-05,\n",
       "            1.1425e-04, 1.0589e-04, 1.0176e-04, 8.5958e-05, 9.0463e-05, 2.1472e-04,\n",
       "            7.1209e-05, 1.2449e-04, 1.0880e-04, 1.2685e-04, 1.2417e-04, 1.2454e-04,\n",
       "            8.2345e-05, 1.1059e-04, 1.0925e-04, 1.2558e-04, 9.4757e-05, 1.4360e-04,\n",
       "            9.8389e-05, 8.9126e-05, 1.2384e-04, 7.0699e-05, 1.0543e-04, 9.4639e-05,\n",
       "            1.0523e-04, 9.1138e-05, 1.8618e-04, 9.5401e-05, 1.3088e-04, 6.6026e-05,\n",
       "            6.7756e-05, 9.8965e-05, 1.6128e-04, 8.1255e-05, 7.4246e-05, 6.9099e-05,\n",
       "            1.1962e-04, 1.8529e-04, 1.1763e-04, 1.8448e-04, 1.7207e-04, 1.5231e-04,\n",
       "            6.8052e-05, 1.5056e-04, 1.0978e-04, 6.7433e-05, 1.2700e-04, 8.3629e-05,\n",
       "            1.3015e-04, 9.3021e-05, 1.0450e-04, 1.2296e-04, 9.6035e-05, 1.1745e-04,\n",
       "            9.0783e-05, 1.4968e-04, 6.5415e-05, 9.3586e-05, 1.0051e-04, 1.0983e-04,\n",
       "            1.4996e-04, 7.5815e-05, 8.7250e-05, 1.0516e-04, 8.7794e-05, 7.0546e-05,\n",
       "            8.9992e-05, 1.0406e-04, 1.2970e-04, 1.1989e-04],\n",
       "           [2.1773e-04, 4.5383e-04, 1.6370e-04, 7.1259e-05, 1.5001e-04, 1.8438e-04,\n",
       "            2.5673e-04, 1.5035e-04, 2.5748e-04, 9.4881e-05, 1.3503e-04, 1.9716e-04,\n",
       "            1.9612e-04, 1.1646e-04, 1.5849e-04, 8.9334e-05, 2.2892e-04, 9.7755e-06,\n",
       "            1.4836e-04, 1.4260e-04, 2.3879e-04, 1.4922e-04, 1.3214e-04, 1.2947e-04,\n",
       "            1.0959e-04, 7.6586e-05, 1.1740e-04, 1.3559e-04, 1.4745e-04, 3.6544e-05,\n",
       "            1.2237e-04, 1.4722e-04, 9.4598e-05, 1.2902e-04, 1.5330e-04, 3.4921e-04,\n",
       "            1.6270e-04, 1.2395e-04, 1.3115e-04, 1.4514e-04, 2.7841e-04, 2.0459e-04,\n",
       "            1.9172e-04, 2.1940e-04, 1.0827e-04, 1.4366e-04, 1.6962e-04, 1.1955e-04,\n",
       "            9.1199e-05, 2.1641e-04, 1.2760e-04, 1.7185e-04, 9.6137e-05, 9.5794e-05,\n",
       "            2.2833e-04, 1.5679e-04, 2.6835e-04, 2.1306e-04, 1.3064e-04, 1.5799e-04,\n",
       "            1.2237e-04, 8.6396e-05, 3.5168e-04, 6.6732e-05, 1.2040e-04, 1.7058e-04,\n",
       "            1.7155e-04, 2.0508e-04, 2.3364e-04, 2.0963e-04, 1.7758e-04, 1.7573e-04,\n",
       "            1.4542e-04, 3.4207e-04, 1.5798e-04, 1.1376e-04, 2.7006e-04, 1.6527e-04,\n",
       "            1.8080e-04, 7.8599e-05, 1.8513e-04, 1.3153e-04, 1.5901e-04, 1.1529e-04,\n",
       "            8.7197e-05, 1.6067e-04, 1.3054e-04, 1.1041e-04, 7.9552e-05, 9.9425e-05,\n",
       "            3.3999e-04, 1.2962e-04, 2.1332e-04, 2.2110e-04, 1.4962e-04, 1.5401e-04,\n",
       "            1.7176e-04, 9.5637e-05, 2.9640e-04, 1.5780e-04]])},\n",
       "  5: {'step': 1000,\n",
       "   'exp_avg': tensor([-5.2359e-05,  3.0482e-05,  2.1876e-05]),\n",
       "   'exp_avg_sq': tensor([0.0005, 0.0006, 0.0009])}},\n",
       " 'param_groups': [{'lr': 0.01,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'params': [0, 1, 2, 3, 4, 5]}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_classifier.pt\n",
      "wine_classifier_state_dict\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'models/wine_classifier_state_dict')\n",
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_state_dict(torch.load('models/wine_classifier_state_dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=13, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9444\n",
      "Precision: 0.9444\n",
      "Recall: 0.9444\n",
      "F1 Score: 0.9444\n"
     ]
    }
   ],
   "source": [
    "predict_out = new_model(Xtest_)\n",
    "_, predict_y = torch.max(predict_out, 1)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(f'Accuracy: {accuracy_score(ytest_, predict_y):.4f}')\n",
    "print(f'Precision: {precision_score(ytest_, predict_y, average=\"micro\"):.4f}')\n",
    "print(f'Recall: {recall_score(ytest_, predict_y, average=\"micro\"):.4f}')\n",
    "print(f'F1 Score: {f1_score(ytest_, predict_y, average=\"micro\"):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5a8803176ba603454a120d2af569b11c3f41e6e81f2a81589e795246afd0d6d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
